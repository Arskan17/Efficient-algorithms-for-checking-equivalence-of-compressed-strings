{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edd69f4",
   "metadata": {},
   "source": [
    "## Old re-pair from [GitHub](https://github.com/fralar-code/Universal-Data-Compression?tab=readme-ov-file#5-re-pair-algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80725027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re_pair import main\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6917d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### 1-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 291\n",
      "############### 1-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 291\n"
     ]
    }
   ],
   "source": [
    "# 16KiB of text from the pizza&chille corpus dna.50MB\n",
    "sizes = [1]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/dna.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "            # text = \"ababaabc\"\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"############### {si}-{S}-KiB ###############\")\n",
    "        start, rules = main(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dna-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=4)\n",
    "        print(\"\\nStart symbol:\", start)\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"############### {si}-{S}-KiB ###############\")\n",
    "        start, rules = main(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dna-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=4)\n",
    "        print(\"\\nStart symbol:\", start)\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c06fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A',\n",
       " {'A4': ('a', 'b'),\n",
       "  'A': ('A4', 'A5'),\n",
       "  'A5': ('b', 'A6'),\n",
       "  'A6': ('b', 'A7'),\n",
       "  'A7': ('a', 'A8'),\n",
       "  'A8': ('A4', 'c')})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"abbbaabc\"\n",
    "\n",
    "main(text, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08765094",
   "metadata": {},
   "source": [
    "## My_re-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3f3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re_pair_0\n",
    "import re_pair_1\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401d5b9",
   "metadata": {},
   "source": [
    "#### - DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec679c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### 2-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 615\n",
      "############### 2-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 615\n",
      "############### 4-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 1166\n",
      "############### 4-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 1166\n",
      "############### 8-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 2238\n",
      "############### 8-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 2238\n"
     ]
    }
   ],
   "source": [
    "sizes = [2, 4, 8]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/dna.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dna-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"\\nStart symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dna-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"\\nStart symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee718e",
   "metadata": {},
   "source": [
    "#### - Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### 1-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 728\n",
      "############### 1-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 728\n",
      "############### 2-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 1165\n",
      "############### 2-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 1165\n",
      "############### 4-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 2034\n",
      "############### 4-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 2034\n",
      "############### 8-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 2964\n",
      "############### 8-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 2964\n",
      "############### 16-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 5381\n",
      "############### 16-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 5381\n",
      "############### 32-A-KiB ###############\n",
      "\n",
      "Start symbol: A\n",
      "Grammar size: 9093\n",
      "############### 32-B-KiB ###############\n",
      "\n",
      "Start symbol: B\n",
      "Grammar size: 9093\n"
     ]
    }
   ],
   "source": [
    "sizes = [1, 2, 4, 8, 16, 32]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/proteins.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/proteins/proteins-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/proteins/proteins-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975ff4c",
   "metadata": {},
   "source": [
    "#### - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c10ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 1-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 545\n",
      "\n",
      "############### 1-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 545\n",
      "\n",
      "############### 2-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 996\n",
      "\n",
      "############### 2-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 996\n",
      "\n",
      "############### 4-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1641\n",
      "\n",
      "############### 4-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1641\n",
      "\n",
      "############### 8-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 2971\n",
      "\n",
      "############### 8-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 2971\n",
      "\n",
      "############### 16-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 5170\n",
      "\n",
      "############### 16-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 5170\n",
      "\n",
      "############### 32-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 8937\n",
      "\n",
      "############### 32-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 8937\n"
     ]
    }
   ],
   "source": [
    "sizes = [1, 2, 4, 8, 16, 32]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/english.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/english/english-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/english/english-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d4f4f",
   "metadata": {},
   "source": [
    "#### - Pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8675d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 1-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 741\n",
      "\n",
      "############### 1-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 741\n",
      "\n",
      "############### 2-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1417\n",
      "\n",
      "############### 2-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1417\n",
      "\n",
      "############### 4-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 2599\n",
      "\n",
      "############### 4-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 2599\n",
      "\n",
      "############### 8-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 5000\n",
      "\n",
      "############### 8-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 5000\n",
      "\n",
      "############### 16-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 9214\n",
      "\n",
      "############### 16-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 9214\n",
      "\n",
      "############### 32-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 17192\n",
      "\n",
      "############### 32-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 17192\n"
     ]
    }
   ],
   "source": [
    "sizes = [1, 2, 4, 8, 16, 32]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/pitches.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/pitches/pitches-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/pitches/pitches-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51839e62",
   "metadata": {},
   "source": [
    "#### - Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3751fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 1-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 532\n",
      "\n",
      "############### 1-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 532\n",
      "\n",
      "############### 2-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 786\n",
      "\n",
      "############### 2-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 786\n",
      "\n",
      "############### 4-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1030\n",
      "\n",
      "############### 4-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1030\n",
      "\n",
      "############### 8-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1749\n",
      "\n",
      "############### 8-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1749\n",
      "\n",
      "############### 16-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 3338\n",
      "\n",
      "############### 16-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 3338\n",
      "\n",
      "############### 32-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 6554\n",
      "\n",
      "############### 32-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 6554\n"
     ]
    }
   ],
   "source": [
    "sizes = [1, 2, 4, 8, 16, 32]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/sources.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/sources/sources-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/sources/sources-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02097b",
   "metadata": {},
   "source": [
    "#### - dblp.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6712232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 1-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 472\n",
      "\n",
      "############### 1-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 472\n",
      "\n",
      "############### 2-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 717\n",
      "\n",
      "############### 2-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 717\n",
      "\n",
      "############### 4-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1079\n",
      "\n",
      "############### 4-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1079\n",
      "\n",
      "############### 8-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 1762\n",
      "\n",
      "############### 8-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 1762\n",
      "\n",
      "############### 16-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 2968\n",
      "\n",
      "############### 16-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 2968\n",
      "\n",
      "############### 32-A-KiB ###############\n",
      "Start symbol: A\n",
      "Grammar size: 4689\n",
      "\n",
      "############### 32-B-KiB ###############\n",
      "Start symbol: B\n",
      "Grammar size: 4689\n"
     ]
    }
   ],
   "source": [
    "sizes = [1, 2, 4, 8, 16, 32]\n",
    "for size in sizes:\n",
    "    try:\n",
    "        with open(\"../pizza&chille corpus/dblp.xml.50MB\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            si = size\n",
    "            text = file.read(1024*si)\n",
    "\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_0.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dblp.xml/xml-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {si}-{S}-KiB ###############\")\n",
    "        rules = re_pair_1.re_pair(text, S)\n",
    "        with open(f'../testing_dataset/pizza&chille corpus_SLP/dblp.xml/xml-{si}KiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Start symbol:\", list(rules.keys())[-1])\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161989d1",
   "metadata": {},
   "source": [
    "## Unary strings grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a20392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unary_string_base_2\n",
    "import unary_string_base_3\n",
    "import json\n",
    "\n",
    "sizes = [2,4,8,16,32,64,128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b92ac7",
   "metadata": {},
   "source": [
    "#### - Base 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e99e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 2MiB-B ###############\n",
      "Grammar size: 43\n",
      "\n",
      "############### 4MiB-B ###############\n",
      "Grammar size: 41\n",
      "\n",
      "############### 8MiB-B ###############\n",
      "Grammar size: 39\n",
      "\n",
      "############### 16MiB-B ###############\n",
      "Grammar size: 39\n",
      "\n",
      "############### 32MiB-B ###############\n",
      "Grammar size: 41\n",
      "\n",
      "############### 64MiB-B ###############\n",
      "Grammar size: 45\n",
      "\n",
      "############### 128MiB-B ###############\n",
      "Grammar size: 53\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    try:\n",
    "        S = 'B'\n",
    "        print(f\"\\n############### {size}MiB-{S} ###############\")\n",
    "        rules = unary_string_base_3.main(length=size*1024*1024)\n",
    "        with open(f'../testing_dataset/unary_string_SLP/base_3_{size}MiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8871bb",
   "metadata": {},
   "source": [
    "#### - Base 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "671f07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### 2MiB-A ###############\n",
      "Grammar size: 21\n",
      "\n",
      "############### 4MiB-A ###############\n",
      "Grammar size: 22\n",
      "\n",
      "############### 8MiB-A ###############\n",
      "Grammar size: 23\n",
      "\n",
      "############### 16MiB-A ###############\n",
      "Grammar size: 24\n",
      "\n",
      "############### 32MiB-A ###############\n",
      "Grammar size: 25\n",
      "\n",
      "############### 64MiB-A ###############\n",
      "Grammar size: 26\n",
      "\n",
      "############### 128MiB-A ###############\n",
      "Grammar size: 27\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    try:\n",
    "        S = 'A'\n",
    "        print(f\"\\n############### {size}MiB-{S} ###############\")\n",
    "        rules = unary_string_base_2.main(length=size*1024*1024)\n",
    "        with open(f'../testing_dataset/unary_string_SLP/base_2_{size}MiB-{S}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(rules, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Grammar size:\", len(rules))\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
